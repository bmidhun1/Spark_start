{"cells": [{"metadata": {}, "cell_type": "code", "source": "from pyspark.sql import SparkSession", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Start Spark connection\nspark = SparkSession.builder.getOrCreate()", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Allocate the numbers 0-999 to an RDD\nnumbers = range(1000)\nrdd = spark.sparkContext.parallelize(numbers)", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize RDD\nprint(rdd.take(2))  # [0, 1]", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "[0, 1]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(rdd.max())    # 999", "execution_count": 6, "outputs": [{"output_type": "stream", "text": "999\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(rdd.getNumPartitions())  ", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "2\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python37", "display_name": "Python 3.7 with Spark", "language": "python3"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}